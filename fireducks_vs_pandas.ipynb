from nbformat import v4 as nbf

# Create a new Jupyter notebook
nb = nbf.new_notebook()

# Define code and markdown cells
cells = []

# Title and introduction
cells.append(nbf.new_markdown_cell("""# üöÄ FireDucks: Fast and Efficient Data Processing with Pandas Compatibility

FireDucks isn't just about reading and querying ‚Äî it integrates beautifully into hybrid workflows where you might want to combine its speed with Pandas flexibility. Here‚Äôs a practical look at some common operations you‚Äôll perform using FireDucks ‚Äî with performance timings to show just how efficient it can be.
"""))

# Installation cell
cells.append(nbf.new_markdown_cell("## ‚öôÔ∏è Installation"))
cells.append(nbf.new_code_cell("""!pip install fireducks"""))

# Load data using FireDucks
cells.append(nbf.new_markdown_cell("## üì• 1. Load Data Using FireDucks"))
cells.append(nbf.new_code_cell("""import fireducks as fpd
import pandas as pd
import numpy as np
import time

# Specify your CSV file path
path = "/content/fake_data.csv"

start = time.time()
df_fd = fpd.pandas.read_csv(path, encoding="ISO-8859-1")
print("Data Loaded in", time.time() - start, "seconds")

# Convert FireDucks DataFrame to Pandas DataFrame
df_fd_pd = df_fd.to_pandas()"""))

# Convert to Pandas
cells.append(nbf.new_markdown_cell("## üîÑ 2. Convert to Pandas for Advanced Manipulations"))
cells.append(nbf.new_code_cell("""# Already converted above as df_fd_pd = df_fd.to_pandas()"""))

# Simulate larger dataset
cells.append(nbf.new_markdown_cell("## üìà 3. Simulate Larger Dataset (Expansion)"))
cells.append(nbf.new_code_cell("""start = time.time()
df_fd_pd = pd.concat([df_fd_pd] * 2)
print("Dataset Expanded in", time.time() - start, "seconds")"""))

# Drop unnecessary columns
cells.append(nbf.new_markdown_cell("## üßπ 4. Drop Unnecessary Columns"))
cells.append(nbf.new_code_cell("""print("Available columns:", df_fd_pd.columns.tolist())

if "Description" in df_fd_pd.columns:
    start = time.time()
    df_fd_pd.drop(columns=["Description"], inplace=True)
    print("Column 'Description' dropped in", time.time() - start, "seconds")
else:
    print("'Description' column not found ‚Äî skipping drop step.")

print("Columns in df_fd_pd:", df_fd_pd.columns.tolist())

start = time.time()
df_fd_pd.drop(columns=["FakeColumn"], inplace=True, errors='ignore')
print("Columns Dropped in", time.time() - start, "seconds")"""))

# Sorting
cells.append(nbf.new_markdown_cell("## üìä 5. Sort by Date or Any Column"))
cells.append(nbf.new_code_cell("""start = time.time()
df_fd_pd = df_fd_pd.sort_values(by=["InvoiceDate"])
print("Sorting Completed in", time.time() - start, "seconds")"""))

# Grouping and Aggregation
cells.append(nbf.new_markdown_cell("## üßÆ 6. Grouping and Aggregation"))
cells.append(nbf.new_code_cell("""start = time.time()
df_fd_pd_grouped = df_fd_pd.groupby("Country")["Quantity"].sum()
print("Grouping Completed in", time.time() - start, "seconds")"""))

# Fake data generation
cells.append(nbf.new_markdown_cell("## üß™ 7. Fake Data Generation (For Testing)"))
cells.append(nbf.new_code_cell("""start = time.time()
df_fd_pd["FakeColumn"] = np.random.randint(1, 100, df_fd_pd.shape[0])
print("Fake Data Generated in", time.time() - start, "seconds")"""))

# String transformation
cells.append(nbf.new_markdown_cell("## üî§ 8. String Transformation (Custom Labels)"))
cells.append(nbf.new_code_cell("""start = time.time()
df_fd_pd["InvoiceNo"] = df_fd_pd["InvoiceNo"].astype(str) + "_FD"
print("String Transformation Completed in", time.time() - start, "seconds")"""))

# Save notebook
nb['cells'] = cells
output_path = "/mnt/data/fireducks_operations.ipynb"

with open(output_path, 'w') as f:
    nbf.write(nb, f)

output_path
