from nbformat import v4 as nbf
from pathlib import Path

# Create a new notebook
nb = nbf.new_notebook()

# Markdown cells
intro = nbf.new_markdown_cell("""
# ⚙️ FireDucks Operations and Descriptions

**FireDucks** isn't just about reading and querying — it integrates beautifully into hybrid workflows where you might want to combine its speed with Pandas flexibility.

This notebook demonstrates common operations with FireDucks, along with performance timings.
""")

installation = nbf.new_code_cell("""
# 🔧 Installation of FireDucks (Uncomment if not installed)
# !pip install fireducks
""")

import_block = nbf.new_code_cell("""
import fireducks as fpd
import pandas as pd
import numpy as np
import time
""")

load_data = nbf.new_code_cell("""
# 📥 1. Load Data Using FireDucks
path = "/content/fake_data.csv"  # Update with your file path

start = time.time()
df_fd = fpd.pandas.read_csv(path, encoding="ISO-8859-1")
print("Data Loaded in", time.time() - start, "seconds")

df_fd_pd = df_fd.to_pandas()
""")

convert_to_pandas = nbf.new_code_cell("""
# 🔄 2. Convert to Pandas for Advanced Manipulations
df_fd_pd = df_fd.to_pandas()
""")

expand_dataset = nbf.new_code_cell("""
# 📈 3. Simulate Larger Dataset (Expansion)
start = time.time()
df_fd_pd = pd.concat([df_fd_pd] * 2)
print("Dataset Expanded in", time.time() - start, "seconds")
""")

drop_columns = nbf.new_code_cell("""
# 🧹 4. Drop Unnecessary Columns
print("Available columns:", df_fd_pd.columns.tolist())

if "Description" in df_fd_pd.columns:
    start = time.time()
    df_fd_pd.drop(columns=["Description"], inplace=True)
    print("Column 'Description' dropped in", time.time() - start, "seconds")
else:
    print("'Description' column not found — skipping drop step.")

# Drop fake column if exists
if "FakeColumn" in df_fd_pd.columns:
    start = time.time()
    df_fd_pd.drop(columns=["FakeColumn"], inplace=True)
    print("FakeColumn dropped in", time.time() - start, "seconds")
""")

sort_column = nbf.new_code_cell("""
# 📊 5. Sort by Date or Any Column
start = time.time()
df_fd_pd = df_fd_pd.sort_values(by=["InvoiceDate"])
print("Sorting Completed in", time.time() - start, "seconds")
""")

groupby_column = nbf.new_code_cell("""
# 🧮 6. Grouping and Aggregation
start = time.time()
df_fd_pd_grouped = df_fd_pd.groupby("Country")["Quantity"].sum()
print("Grouping Completed in", time.time() - start, "seconds")
df_fd_pd_grouped.head()
""")

fake_data_gen = nbf.new_code_cell("""
# 🧪 7. Fake Data Generation (For Testing)
start = time.time()
df_fd_pd["FakeColumn"] = np.random.randint(1, 100, df_fd_pd.shape[0])
print("Fake Data Generated in", time.time() - start, "seconds")
""")

string_transform = nbf.new_code_cell("""
# 🔤 8. String Transformation (Custom Labels)
start = time.time()
df_fd_pd["InvoiceNo"] = df_fd_pd["InvoiceNo"].astype(str) + "_FD"
print("String Transformation Completed in", time.time() - start, "seconds")
""")

# Add all cells to notebook
nb.cells = [
    intro, installation, import_block, load_data, convert_to_pandas,
    expand_dataset, drop_columns, sort_column, groupby_column,
    fake_data_gen, string_transform
]

# Save notebook
path = Path("/mnt/data/f_vs_p.ipynb")
with open(path, "w") as f:
    f.write(nbf.writes(nb))

str(path)
