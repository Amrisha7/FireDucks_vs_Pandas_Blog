# Regenerate the proper .ipynb structure from the provided operations as a Jupyter Notebook

from nbformat import v4 as nbf
from pathlib import Path

# Create a new notebook
nb = nbf.new_notebook()
cells = []

# Markdown and code blocks
cells.append(nbf.new_markdown_cell("# ‚öôÔ∏è FireDucks Operations and Descriptions\n"
"FireDucks isn't just about reading and querying ‚Äî it integrates beautifully into hybrid workflows "
"where you might want to combine its speed with Pandas flexibility. Here‚Äôs a practical look at some "
"common operations you‚Äôll perform using FireDucks ‚Äî with performance timings to show just how efficient it can be."))

# Installation block
cells.append(nbf.new_code_cell("!pip install fireducks"))

# Load data
cells.append(nbf.new_markdown_cell("## üì• 1. Load Data Using FireDucks"))
cells.append(nbf.new_code_cell("""
import fireducks as fpd
import time

path = "/content/fake_data.csv"  # Adjust this to your actual CSV path
start = time.time()
df_fd = fpd.pandas.read_csv(path, encoding="ISO-8859-1")
print("Data Loaded in", time.time() - start, "seconds")
"""))

# Convert to pandas
cells.append(nbf.new_markdown_cell("## üîÑ 2. Convert to Pandas for Advanced Manipulations"))
cells.append(nbf.new_code_cell("df_fd_pd = df_fd.to_pandas()"))

# Expand dataset
cells.append(nbf.new_markdown_cell("## üìà 3. Simulate Larger Dataset (Expansion)"))
cells.append(nbf.new_code_cell("""
import pandas as pd
start = time.time()
df_fd_pd = pd.concat([df_fd_pd] * 2)
print("Dataset Expanded in", time.time() - start, "seconds")
"""))

# Drop unnecessary column
cells.append(nbf.new_markdown_cell("## üßπ 4. Drop Unnecessary Columns"))
cells.append(nbf.new_code_cell("""
print("Available columns:", df_fd_pd.columns.tolist())

# Drop only if 'Description' exists
if "Description" in df_fd_pd.columns:
    start = time.time()
    df_fd_pd.drop(columns=["Description"], inplace=True)
    print("Column 'Description' dropped in", time.time() - start, "seconds")
else:
    print("'Description' column not found ‚Äî skipping drop step.")

# Drop another column (example: 'FakeColumn')
if "FakeColumn" in df_fd_pd.columns:
    start = time.time()
    df_fd_pd.drop(columns=["FakeColumn"], inplace=True)
    print("Columns Dropped in", time.time() - start, "seconds")
"""))

# Sort data
cells.append(nbf.new_markdown_cell("## üìä 5. Sort by Date or Any Column"))
cells.append(nbf.new_code_cell("""
start = time.time()
df_fd_pd = df_fd_pd.sort_values(by=["InvoiceDate"])
print("Sorting Completed in", time.time() - start, "seconds")
"""))

# Grouping data
cells.append(nbf.new_markdown_cell("## üßÆ 6. Grouping and Aggregation"))
cells.append(nbf.new_code_cell("""
start = time.time()
df_fd_pd_grouped = df_fd_pd.groupby("Country")["Quantity"].sum()
print("Grouping Completed in", time.time() - start, "seconds")
"""))

# Fake data generation
cells.append(nbf.new_markdown_cell("## üß™ 7. Fake Data Generation (For Testing)"))
cells.append(nbf.new_code_cell("""
import numpy as np
start = time.time()
df_fd_pd["FakeColumn"] = np.random.randint(1, 100, df_fd_pd.shape[0])
print("Fake Data Generated in", time.time() - start, "seconds")
"""))

# String transformation
cells.append(nbf.new_markdown_cell("## üî§ 8. String Transformation (Custom Labels)"))
cells.append(nbf.new_code_cell("""
start = time.time()
df_fd_pd["InvoiceNo"] = df_fd_pd["InvoiceNo"].astype(str) + "_FD"
print("String Transformation Completed in", time.time() - start, "seconds")
"""))

# Finalize notebook
nb['cells'] = cells

# Save notebook to file
output_path = Path("/mnt/data/f_vs_p.ipynb")
with output_path.open("w", encoding="utf-8") as f:
    f.write(nbf.writes(nb))

output_path.name  # Return filename to user

